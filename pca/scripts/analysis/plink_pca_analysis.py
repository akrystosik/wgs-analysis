#!/usr/bin/env python3
"""
PLINK-based PCA Analysis for Ancestry Inference
Analyzes PC coordinates from PLINK and creates publication-ready plots
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path
import re
import sys
import warnings
warnings.filterwarnings('ignore')

# Set up file paths
base_dir = Path("/mnt/czi-sci-ai/intrinsic-variation-gene-ex/wgs")
pca_dir = base_dir / "pca"
results_dir = pca_dir / "results" / "plink_analysis"
results_dir.mkdir(parents=True, exist_ok=True)

# Load PCA results
def load_pca_results():
    """Load PLINK PCA results"""
    print("Loading PLINK PCA results...")
    
    # Load eigenvalues
    eigenval_file = pca_dir / "data" / "plink_files" / "ancestry_pca.eigenval"
    eigenvals = pd.read_csv(eigenval_file, header=None, names=['eigenval'])
    
    # Calculate variance explained
    total_var = eigenvals['eigenval'].sum()
    eigenvals['var_explained'] = eigenvals['eigenval'] / total_var * 100
    eigenvals['cumvar_explained'] = eigenvals['var_explained'].cumsum()
    
    # Load eigenvectors (PC coordinates)
    eigenvec_file = pca_dir / "data" / "plink_files" / "ancestry_pca.eigenvec"
    pcs = pd.read_csv(eigenvec_file, sep=' ', header=None)
    
    # Set column names
    pc_cols = [f'PC{i+1}' for i in range(pcs.shape[1] - 2)]
    pcs.columns = ['FID', 'IID'] + pc_cols
    
    print(f"Loaded {len(pcs)} samples with {len(pc_cols)} principal components")
    print(f"PC1 explains {eigenvals.iloc[0]['var_explained']:.2f}% of variance")
    print(f"PC2 explains {eigenvals.iloc[1]['var_explained']:.2f}% of variance")
    
    return pcs, eigenvals

# Load ancestry metadata
def load_ancestry_metadata():
    """Load existing ancestry information"""
    print("Loading ancestry metadata...")
    
    # Try to load existing comprehensive ancestry mapping
    try:
        metadata_file = pca_dir / "results" / "comprehensive_ancestry_mapping.csv"
        if metadata_file.exists():
            metadata = pd.read_csv(metadata_file)
            print(f"Loaded ancestry metadata for {len(metadata)} samples")
            return metadata
    except Exception as e:
        print(f"Could not load comprehensive ancestry mapping: {e}")
    
    # Try to load from RNA-seq ethnicity mapping
    try:
        rnaseq_file = Path("/mnt/czi-sci-ai/intrinsic-variation-gene-ex/rnaseq/reports/subject_ethnicity_mapping_czi_compliant.csv")
        if rnaseq_file.exists():
            metadata = pd.read_csv(rnaseq_file)
            print(f"Loaded RNA-seq ethnicity mapping for {len(metadata)} samples")
            return metadata
    except Exception as e:
        print(f"Could not load RNA-seq ethnicity mapping: {e}")
    
    print("No ancestry metadata found - will create basic categories")
    return None

# Load MAGE reference populations
def load_mage_reference_data():
    """Load MAGE reference population data for ancestry assignment"""
    print("Loading MAGE reference population data...")
    
    try:
        donor_summary_file = pca_dir / "results" / "updated_metadata" / "donor_summary.csv"
        if donor_summary_file.exists():
            donor_data = pd.read_csv(donor_summary_file)
            
            # Filter for MAGE samples with known 1KGP ancestry
            mage_refs = donor_data[
                (donor_data['dataset'] == 'MAGE') & 
                (donor_data['mage_1kgp_ancestry'].notna()) &
                (donor_data['PC1'].notna()) & 
                (donor_data['PC2'].notna())
            ].copy()
            
            print(f"Loaded {len(mage_refs)} MAGE reference samples")
            
            # Calculate ancestry centroids in PC space
            centroids = {}
            for ancestry in ['EUR', 'AFR', 'EAS', 'SAS', 'AMR']:
                ancestry_samples = mage_refs[mage_refs['mage_1kgp_ancestry'] == ancestry]
                if len(ancestry_samples) > 0:
                    centroids[ancestry] = {
                        'PC1': ancestry_samples['PC1'].mean(),
                        'PC2': ancestry_samples['PC2'].mean(),
                        'std_PC1': ancestry_samples['PC1'].std(),
                        'std_PC2': ancestry_samples['PC2'].std(),
                        'n_samples': len(ancestry_samples)
                    }
                    print(f"  {ancestry}: n={len(ancestry_samples)}, PC1={centroids[ancestry]['PC1']:.4f}, PC2={centroids[ancestry]['PC2']:.4f}")
            
            return mage_refs, centroids
            
    except Exception as e:
        print(f"Could not load MAGE reference data: {e}")
        return None, None
    
    return None, None

# Create ancestry assignments using reference-guided clustering
def assign_ancestry_from_pca(pcs, metadata=None):
    """Assign ancestry based on reference-guided PCA clustering"""
    print("Assigning ancestry using reference-guided clustering...")
    
    # Create a copy for assignment
    results = pcs.copy()
    
    # Initialize ancestry columns
    results['inferred_ancestry'] = 'Unknown'
    results['data_source'] = 'Unknown'
    results['assignment_confidence'] = 0.0
    results['distance_to_centroid'] = np.inf
    
    # Extract sample info from IID
    results['sample_type'] = results['IID'].apply(lambda x: 
        'ENCODE' if any(cell in x.upper() for cell in ['A549', 'K562', 'HEP', 'CAKI', 'PANC', 'T47D', 'SKNMC', 'NCI', 'GM23248']) else
        'MAGE' if x.startswith('NA') or x.startswith('HG') or (x.startswith('GM') and x != 'GM23248') else
        'GTEx' if x.startswith('GTEX') else
        'ADNI' if 'ADNI' in x.upper() or re.match(r'^\d{3}_S_\d{4}$', x) else
        'Unknown'
    )
    
    # Set data_source based on sample_type
    results['data_source'] = results['sample_type'].apply(lambda x: 
        x if x in ['MAGE', 'GTEx', 'ADNI', 'ENCODE'] else 'Unknown'
    )
    
    # Load MAGE reference data for guided clustering
    mage_refs, centroids = load_mage_reference_data()
    
    if centroids is not None and len(centroids) > 0:
        print("Using reference-guided clustering with MAGE population centroids...")
        
        # For each sample, calculate distance to each ancestry centroid
        for idx, row in results.iterrows():
            pc1, pc2 = row['PC1'], row['PC2']
            
            min_distance = np.inf
            best_ancestry = 'Unknown'
            best_confidence = 0.0
            
            # Calculate distances to each ancestry centroid
            for ancestry, centroid in centroids.items():
                # Euclidean distance to centroid
                distance = np.sqrt((pc1 - centroid['PC1'])**2 + (pc2 - centroid['PC2'])**2)
                
                # Calculate confidence based on distance and population spread
                # Use 2.5 standard deviations as threshold for assignment
                threshold = 2.5 * np.sqrt(centroid['std_PC1']**2 + centroid['std_PC2']**2)
                confidence = max(0, 1 - (distance / threshold)) if threshold > 0 else 0
                
                if distance < min_distance and confidence > 0.3:  # Minimum confidence threshold
                    min_distance = distance
                    best_ancestry = ancestry
                    best_confidence = confidence
            
            # Assign ancestry if confident enough
            if best_confidence > 0.3:  # Conservative threshold
                results.loc[idx, 'inferred_ancestry'] = best_ancestry
                results.loc[idx, 'assignment_confidence'] = best_confidence
                results.loc[idx, 'distance_to_centroid'] = min_distance
        
        print("Reference-guided clustering completed")
        
    else:
        print("MAGE reference data not available - falling back to fixed boundaries...")
        
        # Fallback to fixed boundaries if reference data unavailable
        # European cluster (negative PC1, around 0 PC2)
        eur_mask = (results['PC1'] < -0.005) & (results['PC2'].abs() < 0.01)
        results.loc[eur_mask, 'inferred_ancestry'] = 'EUR'
        results.loc[eur_mask, 'assignment_confidence'] = 0.7
        
        # African cluster (positive PC1, positive PC2)
        afr_mask = (results['PC1'] > 0.005) & (results['PC2'] > 0.005)
        results.loc[afr_mask, 'inferred_ancestry'] = 'AFR'
        results.loc[afr_mask, 'assignment_confidence'] = 0.7
        
        # East Asian cluster (positive PC1, negative PC2)
        eas_mask = (results['PC1'] > 0.005) & (results['PC2'] < -0.005)
        results.loc[eas_mask, 'inferred_ancestry'] = 'EAS'
        results.loc[eas_mask, 'assignment_confidence'] = 0.7
        
        # South Asian cluster (intermediate PC1, intermediate PC2)
        sas_mask = (results['PC1'].between(-0.005, 0.005)) & (results['PC2'].between(-0.005, 0.005))
        results.loc[sas_mask, 'inferred_ancestry'] = 'SAS'
        results.loc[sas_mask, 'assignment_confidence'] = 0.7
    
    # Add metadata if available
    if metadata is not None:
        # Try to match by sample ID
        for idx, row in results.iterrows():
            sample_id = row['IID']
            
            # Look for matching metadata
            matches = metadata[metadata['subject_id'] == sample_id]
            if len(matches) > 0:
                match = matches.iloc[0]
                if 'ethnicity_label_for_reference' in match:
                    results.loc[idx, 'known_ancestry'] = match['ethnicity_label_for_reference']
                if 'dataset' in match:
                    results.loc[idx, 'data_source'] = match['dataset']
    
    print(f"Ancestry assignments:")
    ancestry_counts = results['inferred_ancestry'].value_counts()
    for ancestry, count in ancestry_counts.items():
        pct = count / len(results) * 100
        print(f"  {ancestry}: {count:,} ({pct:.1f}%)")
    
    # Print confidence statistics
    assigned_samples = results[results['inferred_ancestry'] != 'Unknown']
    if len(assigned_samples) > 0:
        print(f"\nAssignment confidence statistics:")
        print(f"  Mean confidence: {assigned_samples['assignment_confidence'].mean():.3f}")
        print(f"  High confidence (>0.7): {(assigned_samples['assignment_confidence'] > 0.7).sum():,}")
        print(f"  Medium confidence (0.5-0.7): {((assigned_samples['assignment_confidence'] >= 0.5) & (assigned_samples['assignment_confidence'] <= 0.7)).sum():,}")
        print(f"  Low confidence (0.3-0.5): {((assigned_samples['assignment_confidence'] >= 0.3) & (assigned_samples['assignment_confidence'] < 0.5)).sum():,}")
    
    return results

# Create visualizations
def create_pca_plots(results, eigenvals):
    """Create comprehensive PCA plots"""
    print("Creating PCA visualizations...")
    
    # Set up the plotting style
    plt.style.use('default')
    sns.set_palette("husl")
    
    # Create figure with subplots
    fig, axes = plt.subplots(2, 2, figsize=(16, 12))
    fig.suptitle('PLINK-based Ancestry PCA Analysis\n2.88M Ancestry-Informative Markers', fontsize=16, fontweight='bold')
    
    # Plot 1: PC1 vs PC2 colored by inferred ancestry
    ax1 = axes[0, 0]
    ancestry_colors = {
        'EUR': '#1f77b4',
        'AFR': '#ff7f0e', 
        'EAS': '#2ca02c',
        'SAS': '#d62728',
        'AMR': '#9467bd',
        'Unknown': '#7f7f7f'
    }
    
    for ancestry in results['inferred_ancestry'].unique():
        mask = results['inferred_ancestry'] == ancestry
        if mask.sum() > 0:
            ax1.scatter(results.loc[mask, 'PC1'], results.loc[mask, 'PC2'], 
                       c=ancestry_colors.get(ancestry, '#7f7f7f'), 
                       label=f'{ancestry} (n={mask.sum()})', alpha=0.7, s=20)
    
    ax1.set_xlabel(f'PC1 ({eigenvals.iloc[0]["var_explained"]:.2f}%)')
    ax1.set_ylabel(f'PC2 ({eigenvals.iloc[1]["var_explained"]:.2f}%)')
    ax1.set_title('PC1 vs PC2 - Inferred Ancestry')
    ax1.legend()
    ax1.grid(True, alpha=0.3)
    
    # Plot 2: PC1 vs PC2 colored by sample type
    ax2 = axes[0, 1]
    sample_colors = {
        'MAGE': '#e377c2',
        'GTEx': '#17becf',
        'ADNI': '#bcbd22',
        'ENCODE': '#ff7f0e',
        'Unknown': '#7f7f7f'
    }
    
    for sample_type in results['sample_type'].unique():
        mask = results['sample_type'] == sample_type
        if mask.sum() > 0:
            ax2.scatter(results.loc[mask, 'PC1'], results.loc[mask, 'PC2'],
                       c=sample_colors.get(sample_type, '#7f7f7f'),
                       label=f'{sample_type} (n={mask.sum()})', alpha=0.7, s=20)
    
    ax2.set_xlabel(f'PC1 ({eigenvals.iloc[0]["var_explained"]:.2f}%)')
    ax2.set_ylabel(f'PC2 ({eigenvals.iloc[1]["var_explained"]:.2f}%)')
    ax2.set_title('PC1 vs PC2 - Sample Type')
    ax2.legend()
    ax2.grid(True, alpha=0.3)
    
    # Plot 3: PC1 vs PC3
    ax3 = axes[1, 0]
    for ancestry in results['inferred_ancestry'].unique():
        mask = results['inferred_ancestry'] == ancestry
        if mask.sum() > 0:
            ax3.scatter(results.loc[mask, 'PC1'], results.loc[mask, 'PC3'],
                       c=ancestry_colors.get(ancestry, '#7f7f7f'),
                       label=f'{ancestry} (n={mask.sum()})', alpha=0.7, s=20)
    
    ax3.set_xlabel(f'PC1 ({eigenvals.iloc[0]["var_explained"]:.2f}%)')
    ax3.set_ylabel(f'PC3 ({eigenvals.iloc[2]["var_explained"]:.2f}%)')
    ax3.set_title('PC1 vs PC3 - Inferred Ancestry')
    ax3.legend()
    ax3.grid(True, alpha=0.3)
    
    # Plot 4: Variance explained
    ax4 = axes[1, 1]
    pcs_to_plot = min(10, len(eigenvals))
    ax4.bar(range(1, pcs_to_plot + 1), eigenvals.iloc[:pcs_to_plot]['var_explained'],
            alpha=0.7, color='skyblue')
    ax4.set_xlabel('Principal Component')
    ax4.set_ylabel('Variance Explained (%)')
    ax4.set_title('Variance Explained by Top 10 PCs')
    ax4.set_xticks(range(1, pcs_to_plot + 1))
    ax4.grid(True, alpha=0.3)
    
    # Add text with summary statistics
    total_var_top3 = eigenvals.iloc[:3]['var_explained'].sum()
    ax4.text(0.7, 0.8, f'Top 3 PCs: {total_var_top3:.1f}%', 
             transform=ax4.transAxes, bbox=dict(boxstyle="round", facecolor='white', alpha=0.8))
    
    plt.tight_layout()
    
    # Save the plot
    plot_file = results_dir / "plink_pca_analysis.png"
    plt.savefig(plot_file, dpi=300, bbox_inches='tight')
    print(f"Saved PCA plot to {plot_file}")
    
    plt.show()

# Generate summary report
def generate_summary_report(results, eigenvals):
    """Generate a comprehensive summary report"""
    print("Generating summary report...")
    
    # Calculate summary statistics
    report = []
    report.append("# PLINK-based Ancestry PCA Analysis Report")
    report.append("=" * 50)
    report.append("")
    
    report.append("## Dataset Overview")
    report.append(f"- Total samples: {len(results):,}")
    report.append(f"- Ancestry-informative markers: 2,884,699")
    report.append(f"- Principal components calculated: 20")
    report.append("")
    
    report.append("## Variance Explained")
    for i in range(min(5, len(eigenvals))):
        report.append(f"- PC{i+1}: {eigenvals.iloc[i]['var_explained']:.2f}%")
    report.append(f"- Top 5 PCs combined: {eigenvals.iloc[:5]['var_explained'].sum():.2f}%")
    report.append("")
    
    report.append("## Sample Composition by Data Source")
    sample_counts = results['sample_type'].value_counts()
    for sample_type, count in sample_counts.items():
        pct = count / len(results) * 100
        report.append(f"- {sample_type}: {count:,} ({pct:.1f}%)")
    report.append("")
    
    report.append("## Inferred Ancestry Distribution")
    ancestry_counts = results['inferred_ancestry'].value_counts()
    for ancestry, count in ancestry_counts.items():
        pct = count / len(results) * 100
        report.append(f"- {ancestry}: {count:,} ({pct:.1f}%)")
    report.append("")
    
    report.append("## Quality Metrics")
    report.append(f"- PC1 variance: {eigenvals.iloc[0]['var_explained']:.2f}% (âœ… >8% target met)")
    report.append(f"- PC2 variance: {eigenvals.iloc[1]['var_explained']:.2f}%")
    report.append(f"- Ancestry assignment rate: {((results['inferred_ancestry'] != 'Unknown').sum() / len(results) * 100):.1f}%")
    report.append("")
    
    report.append("## Methodology")
    report.append("- LD pruning: 50kb windows, 5 SNP steps, rÂ² < 0.2")
    report.append("- PCA: PLINK v1.90b6.24 with 2.88M markers")
    report.append("- Ancestry assignment: Reference-guided clustering using MAGE 1000 Genomes centroids")
    report.append("- Assignment threshold: 2.5 standard deviations from population centroids")
    report.append("- Minimum confidence: 0.3 for ancestry assignment")
    report.append("- Quality control: MAF > 0.01, biallelic variants only")
    
    # Add confidence distribution if available
    assigned_samples = results[results['inferred_ancestry'] != 'Unknown']
    if len(assigned_samples) > 0 and 'assignment_confidence' in assigned_samples.columns:
        report.append("")
        report.append("## Assignment Confidence Distribution")
        high_conf = (assigned_samples['assignment_confidence'] > 0.7).sum()
        med_conf = ((assigned_samples['assignment_confidence'] >= 0.5) & (assigned_samples['assignment_confidence'] <= 0.7)).sum()
        low_conf = ((assigned_samples['assignment_confidence'] >= 0.3) & (assigned_samples['assignment_confidence'] < 0.5)).sum()
        
        report.append(f"- High confidence (>0.7): {high_conf:,} ({high_conf/len(assigned_samples)*100:.1f}%)")
        report.append(f"- Medium confidence (0.5-0.7): {med_conf:,} ({med_conf/len(assigned_samples)*100:.1f}%)")
        report.append(f"- Low confidence (0.3-0.5): {low_conf:,} ({low_conf/len(assigned_samples)*100:.1f}%)")
        report.append(f"- Mean confidence: {assigned_samples['assignment_confidence'].mean():.3f}")
    
    # Save report
    report_file = results_dir / "plink_pca_analysis_report.txt"
    with open(report_file, 'w') as f:
        f.write('\n'.join(report))
    
    print(f"Saved analysis report to {report_file}")
    
    return report

# Save results
def save_results(results, eigenvals):
    """Save all results to CSV files"""
    print("Saving results...")
    
    # Save PC coordinates with ancestry assignments
    results_file = results_dir / "plink_pca_results.csv"
    results.to_csv(results_file, index=False)
    print(f"Saved PC coordinates to {results_file}")
    
    # Save variance explained
    variance_file = results_dir / "plink_pca_variance_explained.csv"
    eigenvals.to_csv(variance_file, index=False)
    print(f"Saved variance explained to {variance_file}")
    
    # Save ancestry summary
    ancestry_summary = results.groupby(['sample_type', 'inferred_ancestry']).size().reset_index(name='count')
    ancestry_summary_file = results_dir / "plink_ancestry_summary.csv"
    ancestry_summary.to_csv(ancestry_summary_file, index=False)
    print(f"Saved ancestry summary to {ancestry_summary_file}")

def main():
    """Main analysis function"""
    print("Starting PLINK-based PCA Analysis...")
    print("=" * 50)
    
    # Load data
    pcs, eigenvals = load_pca_results()
    metadata = load_ancestry_metadata()
    
    # Assign ancestry
    results = assign_ancestry_from_pca(pcs, metadata)
    
    # Create visualizations
    create_pca_plots(results, eigenvals)
    
    # Generate report
    generate_summary_report(results, eigenvals)
    
    # Save results
    save_results(results, eigenvals)
    
    print("\nAnalysis complete! ðŸŽ‰")
    print(f"Results saved to: {results_dir}")

if __name__ == "__main__":
    main()